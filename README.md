# Text-summarization-with-LSTM
Our project focuses on the application of Natural Language Processing (NLP) techniques to the challenging task of text summarization. The goal is to develop efficient and effective methods for condensing textual content while retaining its key information.
The seq2seq model with attention excels in generating abstractive summaries, offering a creative and concise approach to condensing textual content. 
It can handle variability in input lengths and produce concise summaries irrespective of the input text's length
![image](https://github.com/Bochraboubou/Text-summarization-with-LSTM/assets/72579521/4c596b3a-f8df-4bbc-9623-eb08ca7e9650)

