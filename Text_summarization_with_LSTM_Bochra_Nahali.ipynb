{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muPhOOq_QZVJ"
      },
      "source": [
        "# ***Adding requirement for attention layer***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNER2PiRQZVS"
      },
      "source": [
        "# ***importing required libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jpu8qLEFxcY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import warnings\n",
        "from attention import AttentionLayer\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Hk-_IkQZVV"
      },
      "source": [
        "# ***Loading dataset to the notebook***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnK5o4Z1Fxcj"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv(\"Reviews.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlfMfX1iQZVX"
      },
      "source": [
        "# ***Dropping duplicate reviews and null values***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cjul88oOFxcr"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)#dropping na"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDT3Sbu7QZVZ"
      },
      "source": [
        "# ***Information about datatypes and shape of the dataset***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__fy-JxTFxc9",
        "outputId": "8680dc66-103f-40a5-d2ea-a02157667df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 56497 entries, 0 to 61945\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   Id                      56497 non-null  int64 \n",
            " 1   ProductId               56497 non-null  object\n",
            " 2   UserId                  56497 non-null  object\n",
            " 3   ProfileName             56497 non-null  object\n",
            " 4   HelpfulnessNumerator    56497 non-null  int64 \n",
            " 5   HelpfulnessDenominator  56497 non-null  int64 \n",
            " 6   Score                   56497 non-null  int64 \n",
            " 7   Time                    56497 non-null  int64 \n",
            " 8   Summary                 56497 non-null  object\n",
            " 9   Text                    56497 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 4.7+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imADFQxUQZVa"
      },
      "source": [
        "# ***Dictionary for expanding the contractions***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s6IY-x2FxdL"
      },
      "outputs": [],
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cVbQ-QjQZVb"
      },
      "source": [
        "# ***For removing stopwords***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZr-u3OEFxdT",
        "outputId": "1e434856-6809-40bb-d931-9b73a2a57bb2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQwviUloQZVc"
      },
      "source": [
        "# ***Function for cleaning reviews and summaries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lmawXdCQZVd"
      },
      "outputs": [],
      "source": [
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])\n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)\n",
        "    return (\" \".join(long_words)).strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzM6eMkwQZVd"
      },
      "source": [
        "# ***cleaning reviews and displaying***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2QAeCHWFxdY",
        "outputId": "a9dc2924-6537-400c-d0c1-5300242d3033"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
              " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#call the function\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0))\n",
        "cleaned_text[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-S_apTJQZVe"
      },
      "source": [
        "# ***cleaning summaries and displaying***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsRXocxoFxd-",
        "outputId": "3083098b-d82c-450e-d130-df2d422f06a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine',\n",
              " 'great taffy',\n",
              " 'nice taffy',\n",
              " 'great just as good as the expensive brands',\n",
              " 'wonderful tasty taffy',\n",
              " 'yay barley',\n",
              " 'healthy dog food']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#call the function\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))\n",
        "cleaned_summary[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZSs8np7QZVh"
      },
      "source": [
        "# ***Adding columns into the dataset***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1zLpnqsFxey"
      },
      "outputs": [],
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKAicClGQZVh"
      },
      "source": [
        "# ***Dropping empty rows***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYK390unFxfA"
      },
      "outputs": [],
      "source": [
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY2mQOghQZVi"
      },
      "source": [
        "# ***Visualization distribution of reviews and summaries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "MdF76AHHFxgw",
        "outputId": "2651cda0-9072-4867-bbbd-97f5dc155ed0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JRjwdIOFxg3",
        "outputId": "503ac4ea-c7a5-4ba0-810f-b59df93e7763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9794685562444642\n"
          ]
        }
      ],
      "source": [
        "cnt=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=10):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_summary']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tTVc_H7QZVi",
        "outputId": "c570a31d-c35a-44ef-c4e5-f5fc8cd53232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9132329495128432\n"
          ]
        }
      ],
      "source": [
        "cnt=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=80):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKD5VOWqFxhC"
      },
      "outputs": [],
      "source": [
        "max_text_len=80\n",
        "max_summary_len=10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTxC_-E-QZVj"
      },
      "source": [
        "# ***getting rid of outliers***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY0tEJP0FxhI"
      },
      "outputs": [],
      "source": [
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "\n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-s-nqeRQZVk"
      },
      "source": [
        "# ***Adding tokens at the beginning and the end of summary***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwLUH78CFxhg"
      },
      "outputs": [],
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6UM7jT3QZVl",
        "outputId": "d552a4b0-8ecf-4e2d-88ec-bb205d68bcec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
            "Summary: sostok good quality dog food eostok\n",
            "\n",
            "\n",
            "Review: product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
            "Summary: sostok not as advertised eostok\n",
            "\n",
            "\n",
            "Review: confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
            "Summary: sostok delight says it all eostok\n",
            "\n",
            "\n",
            "Review: looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n",
            "Summary: sostok cough medicine eostok\n",
            "\n",
            "\n",
            "Review: great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
            "Summary: sostok great taffy eostok\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(\"Review:\",df['text'][i])\n",
        "    print(\"Summary:\",df['summary'][i])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceArl2LfQZVl"
      },
      "source": [
        "# ***splitting traing and test set***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RakakKHcFxhl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.05,random_state=0,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3skoqklQZVm"
      },
      "source": [
        "# ***prepare a tokenizer for reviews on training data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRHTgX6hFxhq"
      },
      "outputs": [],
      "source": [
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myky5oL3QZVm"
      },
      "source": [
        "# ***calculating number of rare and common words in reviews***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8KronV2Fxhx",
        "outputId": "f8fbde89-1be8-44e9-d321-097ed4f6bc98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 64.17095115681234\n",
            "Total Coverage of rare words: 2.1426045268783405\n"
          ]
        }
      ],
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "\n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS-dIuT7QZVt"
      },
      "source": [
        "# ***defining tokenizer with most common words for reviews***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2giEsF3Fxh3"
      },
      "outputs": [],
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt)\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr)\n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCbGMsm4FxiA",
        "outputId": "ee543fa8-416a-4b1e-fcaa-68e4e9ab2cba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12266"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_voc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-Nm9s9FQZVu"
      },
      "source": [
        "# ***prepare a tokenizer for summaries on training data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRHqyBkBFxiJ"
      },
      "outputs": [],
      "source": [
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DYk5KCdQZVv"
      },
      "source": [
        "# ***calculating number of rare and common words in summaries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzE5OiRLFxiM",
        "outputId": "bc3a2b38-b277-47f1-ba22-8159c0c6b2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 76.86006825938566\n",
            "Total Coverage of rare words: 4.9280203494640356\n"
          ]
        }
      ],
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "\n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZoVe6_HQZVv"
      },
      "source": [
        "# ***defining tokenizer with most common words for summaries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fswLvIgFxiR"
      },
      "outputs": [],
      "source": [
        "#prepare a tokenizer for summaries on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt)\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr)\n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqPJ8MAaQZVw"
      },
      "source": [
        "# ***checking word count of start token is equal to length of the training data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR8IX9FRFxiY",
        "outputId": "4af9a449-a622-4f66-9c50-887f5703478d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48196, 48196)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h33n4a9_QZVw"
      },
      "source": [
        "# ***deleting the rows that contain only START and END tokens***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ-vW82sFxih"
      },
      "outputs": [],
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx5NISuMFxik"
      },
      "outputs": [],
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPkcfMl9QZVx"
      },
      "source": [
        "# ***Model building, defining LSTM layers, Encoder and Decoder***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXef38nBFxir",
        "outputId": "b18c3910-c940-461a-e22d-b9b2fa0ce5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 80)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 80, 100)              1226600   ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 80, 300),            481200    ['embedding[0][0]']           \n",
            "                              (None, 300),                                                        \n",
            "                              (None, 300)]                                                        \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, 80, 300),            721200    ['lstm[0][0]']                \n",
            "                              (None, 300),                                                        \n",
            "                              (None, 300)]                                                        \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 100)            237400    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               [(None, 80, 300),            721200    ['lstm_1[0][0]']              \n",
            "                              (None, 300),                                                        \n",
            "                              (None, 300)]                                                        \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               [(None, None, 300),          481200    ['embedding_1[0][0]',         \n",
            "                              (None, 300),                           'lstm_2[0][1]',              \n",
            "                              (None, 300)]                           'lstm_2[0][2]']              \n",
            "                                                                                                  \n",
            " attention_layer (Attention  ((None, None, 300),          180300    ['lstm_2[0][0]',              \n",
            " Layer)                       (None, None, 80))                      'lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)  (None, None, 600)            0         ['lstm_3[0][0]',              \n",
            "                                                                     'attention_layer[0][0]']     \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, None, 2374)           1426774   ['concat_layer[0][0]']        \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5475874 (20.89 MB)\n",
            "Trainable params: 5475874 (20.89 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lwfi1Fm8Fxiz"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0sTJNZMQZVy"
      },
      "source": [
        "# ***monitoring the validation loss***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-A3J92MUljB"
      },
      "outputs": [],
      "source": [
        "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2),\n",
        "      ModelCheckpoint('./MyModel_tf',monitor='val_loss', verbose=1,\n",
        "                      save_best_only=True, mode='min', save_weights_only = False)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GVYMwopQZVy"
      },
      "source": [
        "# ***train the model on a batch size of 512 and validate it on the 10% of dataset***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETnPzA4OFxi3",
        "outputId": "38bc9d4a-6547-4ad4-a2f3-08fff954e728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 3.2022 \n",
            "Epoch 1: val_loss improved from inf to 2.86844, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1380s 15s/step - loss: 3.2022 - val_loss: 2.8684\n",
            "Epoch 2/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.6269 \n",
            "Epoch 2: val_loss improved from 2.86844 to 2.54725, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1342s 14s/step - loss: 2.6269 - val_loss: 2.5473\n",
            "Epoch 3/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.5169 \n",
            "Epoch 3: val_loss improved from 2.54725 to 2.52157, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1318s 14s/step - loss: 2.5169 - val_loss: 2.5216\n",
            "Epoch 4/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.4852 \n",
            "Epoch 4: val_loss improved from 2.52157 to 2.47961, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1285s 14s/step - loss: 2.4852 - val_loss: 2.4796\n",
            "Epoch 5/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.4505 \n",
            "Epoch 5: val_loss improved from 2.47961 to 2.44721, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1305s 14s/step - loss: 2.4505 - val_loss: 2.4472\n",
            "Epoch 6/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.4259 \n",
            "Epoch 6: val_loss improved from 2.44721 to 2.43833, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1336s 14s/step - loss: 2.4259 - val_loss: 2.4383\n",
            "Epoch 7/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.4018 \n",
            "Epoch 7: val_loss improved from 2.43833 to 2.40784, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1323s 14s/step - loss: 2.4018 - val_loss: 2.4078\n",
            "Epoch 8/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.3776 \n",
            "Epoch 8: val_loss improved from 2.40784 to 2.37591, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1325s 14s/step - loss: 2.3776 - val_loss: 2.3759\n",
            "Epoch 9/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.3485 \n",
            "Epoch 9: val_loss improved from 2.37591 to 2.35072, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1324s 14s/step - loss: 2.3485 - val_loss: 2.3507\n",
            "Epoch 10/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.3225 \n",
            "Epoch 10: val_loss improved from 2.35072 to 2.32892, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1310s 14s/step - loss: 2.3225 - val_loss: 2.3289\n",
            "Epoch 11/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.3014 \n",
            "Epoch 11: val_loss improved from 2.32892 to 2.32192, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1327s 14s/step - loss: 2.3014 - val_loss: 2.3219\n",
            "Epoch 12/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 2.2829 \n",
            "Epoch 12: val_loss improved from 2.32192 to 2.30367, saving model to ./MyModel_tf\n",
            "93/93 [==============================] - 1307s 14s/step - loss: 2.2829 - val_loss: 2.3037\n",
            "Epoch 13/50\n",
            "23/93 [======>.......................] - ETA: 15:41 - loss: 2.2868"
          ]
        }
      ],
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw25pnLZQZVz"
      },
      "outputs": [],
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"summary.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"summary.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHqcegCOQZVz"
      },
      "source": [
        "\\# ***understanding the behavior of model over time***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDTNLAURFxjE"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBswO5zFQZVz"
      },
      "source": [
        "# ***convert the index to word for summaries and reviews vocabulary***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBX0zZnOFxjW"
      },
      "outputs": [],
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HkvmKPNQZV0"
      },
      "source": [
        "# ***Setting up the inference for the encoder and decoder***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QkrNV-4Fxjt"
      },
      "outputs": [],
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oeGaT97QZV1"
      },
      "source": [
        "# ***Defining a functio for implementation of the inference process***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f6TTFnBFxj6"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYDZgVNRQZV2"
      },
      "source": [
        "# ***converting an integer sequence to a word sequence for summaries and reviews***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAUntznIFxj9"
      },
      "outputs": [],
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKZVfE2QQZV2"
      },
      "source": [
        "# ***displaying some summaries generated by the model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUtQmQTmFxkI"
      },
      "outputs": [],
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHzZ6EcGQZV3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNWIBMVpQZV3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 18,
          "sourceId": 2157,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 717875,
          "sourceId": 1249711,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 29956,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}